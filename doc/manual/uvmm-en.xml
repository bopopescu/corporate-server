<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE chapter [
	<!ENTITY % extensions SYSTEM "../stylesheets/macros.ent" >
	<!ENTITY % DocBookDTD PUBLIC "-//OASIS//DTD DocBook XML V4.5//EN"
	"http://www.oasis-open.org/docbook/xml/4.5/docbookx.dtd">
	<!ENTITY % entities SYSTEM "../stylesheets/macros-en.ent" >
	%extensions;
	%DocBookDTD;
	%entities;
]>
<chapter id="uvmm:chapter">
	<title>Virtualization</title>
	<section id="uvmm::introduction">
		<title>Introduction</title>
		<para>
			&ucsUVMM; (UVMM) is a tool for the administration of hybrid cloud environments.
			It allows central monitoring and administration of KVM virtualization servers
			registered in the UCS domain and virtual machines operated on it. In addition,
			virtual machines can be administered in OpenStack or EC2 environments. The
			administration is performed via the &ucsUMC; module
			<emphasis>Virtual machines</emphasis>.
		</para>
		<para>
			In principle, any operating system can be used on the virtualized systems.
		</para>

	</section>

	<section id="uvmm::installation">
		<title>Installation</title>

		<para>
		  &ucsUVMM; can be installed from the Univention App Center with the application
		  <emphasis>&ucsUVMM;</emphasis>. Alternatively, the software package
		  <package>univention-virtual-machine-manager-daemon</package> can be installed.
		  Additional information can be found in
		  <xref linkend="computers::softwaremanagement::installsoftware"/>.
		</para>

		<para>
			Administration of OpenStack cloud instances is possible directly after
			installation of the application with the &ucsUMC; module <emphasis>Virtual
			machines (UVMM)</emphasis>. The <emphasis>Amazon EC2 Cloud Connection</emphasis>
			application needs to be installed for the administration of virtual machines in
			the Amazon EC2 cloud.
		</para>
		<para>
			To add a KVM virtualization server for the administration via &ucsUVMM; locally,
			the <emphasis>KVM virtualization server</emphasis> application must be installed
			on a server of the domain from the Univention App Center. The application can
			also be selected directly during the installation of a new UCS server.
			Alternatively, the software package
			<package>univention-virtual-machine-manager-node-kvm</package> can be
			installed.
		</para>
		<para>
			CPU virtualization support is mandatory for the operation of KVM. This
			is provided by almost all current x86 CPUs. For more information, consult the
			KVM project website: <ulink url="http://www.linux-kvm.org/"/>.
		</para>

		<para>
			Additionally, the architecture must also be taken into account during
			installation of a virtualization server. 64-bit systems can only be virtualized
			on UCS systems which are installed using the amd64 architecture. A 64-bit system
			(amd64) is recommended for use as the virtualization server.
		</para>
	</section>
	<section id="uvmm::cloudconnections">
		<title>Creating connections to cloud computing instances</title>
		<para>
			&ucsUVMM; supports connections to OpenStack. Installation of the application
			<emphasis>Amazon EC2 cloud connection</emphasis> makes administration of virtual
			machines on the Amazon EC2 cloud possible.
		</para>
		<para>
			To create a new connection, the &ucsUMC; module <emphasis>Virtual machines
			(UVMM)</emphasis> must be opened. Clicking on <guimenu>Create</guimenu> opens a
			wizard in which the <guimenu>Create a new cloud connection</guimenu> entry needs
			to be selected. In the drop-down field that appears you can now select the type
			of connection. Clicking on <guimenu>Next</guimenu> starts the set-up wizard.
			Once you have made the settings, clicking on <guimenu>Finish</guimenu> creates
			the connection. If an error occurs, it is displayed and the connection settings
			can be corrected. If the connection is established successfully, a wait
			animation is shown while the connection-specific information for the cloud
			connection is loaded. This covers for example the existing instances and
			available images for creating new instances.
		</para>
		<section id="uvmm:cloudconnections::openstack">
			<title>Creating an OpenStack connection</title>
			<figure id="uvmm-new-openstack-connection">
				<title>Creating a new connection to an OpenStack instance</title>
				<graphic scalefit="1" width="90%" align="center" fileref="illustrations44/uvmm_new_openstack_connection_en.png"/>
			</figure>
			<para>
				The following settings need to be made in the set-up wizard for creating a
				connection to an OpenStack instance:
				<table>
					<title>Fields when setting up an OpenStack connection</title>
					<tgroup cols="2">
						<colspec colnum="1" colname="col1" colwidth="1*"/>
						<colspec colnum="2" colname="col2" colwidth="2*"/>
						<thead>
							<row>
								<entry>Attribute</entry>
								<entry>Description</entry>
							</row>
						</thead>
						<tbody>
							<row>
								<entry>Name</entry>
								<entry>
									Sets the name of the connection. This will later be shown in the tree view of the
									&ucsUMC; module.
								</entry>
							</row>
							<row>
								<entry>Username</entry>
								<entry>
									The user name to be used for authentication for OpenStack.
								</entry>
							</row>
							<row>
								<entry>Use the following authentication type</entry>
								<entry>
									There are two options to choose from. The corresponding value is entered in the
									field below.
									<variablelist>
										<varlistentry>
											<term>Password</term>
											<listitem>
												<simpara>
													The password corresponding to the user name.
												</simpara>
											</listitem>
										</varlistentry>
										<varlistentry>
											<term>API key</term>
											<listitem>
												<simpara>
													The API key that allows the user access.
												</simpara>
											</listitem>
										</varlistentry>
									</variablelist>
								</entry>
							</row>
							<row>
								<entry>Authentication URL endpoint</entry>
								<entry>
									The URL under which the authentication end point of the OpenStack instance can
									be reached should be entered here. If you want to establish an encrypted
									connection, the URL should be entered in the form
									<uri>https://[...]</uri>. As the public certificate for the OpenStack
									instance is used for the encrypted connection, this certificate needs to be made
									available on the UCS system on which the <emphasis>&ucsUVMM;</emphasis> application
									is installed. To this end, the public certificate must be copied into the
									<filename class="directory">/usr/local/share/ca-certificates/</filename> directory on the UCS
									server in PEM encryption and furnished with the suffix <filename class="extension">.crt</filename>. The following
									commands convert a certificate into the correct encryption and make the
									certificate known.
									<programlisting language="sh">
openssl x509 -in [path/to/openstack-certificate] \
	-outform pem -out /usr/local/share/ca-certificates/openstack.crt

update-ca-certificates
									</programlisting>
									The public certificate of the OpenStack authentication end point should be taken
									from the configuration of the OpenStack instance. The corresponding value to the
									certificate's path can be found under <property>ca_certs</property> in
									<filename>keystone.conf</filename>.
								</entry>
							</row>
							<row>
								<entry>Search pattern for images</entry>
								<entry>
									To create a new virtual machine, only the images that correspond to the
									configured search template are used as source images. The default value "*"
									(asterisk) is used to show all available images.
								</entry>
							</row>
							<row>
								<entry>Project / tenant</entry>
								<entry>
									The project or tenant name assigned to the user within the OpenStack
									environment.
								</entry>
							</row>
							<row>
								<entry>Service region</entry>
								<entry>
									The name of the region in which the user should work. The OpenStack default
									value is <userinput>regionOne</userinput>.
								</entry>
							</row>
							<row>
								<entry>Service type</entry>
								<entry>
									The type of the service under which the cloud compute function is available. The
									default value is <userinput>compute</userinput>.
								</entry>
							</row>
							<row>
								<entry>Service</entry>
								<entry>
									The name of the service under which the cloud compute function is available. The
									default value is <userinput>nova</userinput>.
								</entry>
							</row>
							<row>
								<entry>Service URL endpoint</entry>
								<entry>
									Optional value: The URL of the service end point is normally determined
									automatically when the user logs on to OpenStack. Should automatically
									determination not be possible, the corresponding URL can be entered here.
								</entry>
							</row>
						</tbody>
					</tgroup>
				</table>
			</para>
		</section>
		<section id="uvmm:cloudconnections::amazonec2">
			<title>Creating an EC2 connection</title>
			<para>
				The following settings need to be made in the set-up wizard for creating a
				connection to Amazon EC2:
				<table>
					<title>Fields when setting up an Amazon EC2 connection</title>
					<tgroup cols="2">
						<colspec colnum="1" colname="col1" colwidth="1*"/>
						<colspec colnum="2" colname="col2" colwidth="2*"/>
						<thead>
							<row>
								<entry>Attribute</entry>
								<entry>Description</entry>
							</row>
						</thead>
						<tbody>
							<row>
								<entry>Name</entry>
								<entry>
									Sets the name of the connection This will later be shown in the tree view of the
									&ucsUMC; module.
								</entry>
							</row>
							<row>
								<entry>EC2 region</entry>
								<entry>
									Here you select the EC2 region to which you want to create the connection.
									Virtual machines are always assigned to precisely one region and not visible in
									other regions. The selection of available images can also vary depending on the
									region. Univention UCS images are available in all supported regions.
								</entry>
							</row>
							<row>
								<entry>Access Key ID</entry>
								<entry>
									The access key ID assigned to the Amazon EC2 account is comparable with a user
									name.
								</entry>
							</row>
							<row>
								<entry>Secret Access Key</entry>
								<entry>
									The secret access key for access via the Amazon EC2 account is comparable with a
									password.
								</entry>
							</row>
							<row>
								<entry>Search pattern for AMIs</entry>
								<entry>
									Image files used as a source for new instances are referred to as AMIs. The
									search filter specified here restricts the display of selectable AMIs when
									creating a new virtual instance. The default value "*" (asterisk) is used to
									show all available images.
								</entry>
							</row>
						</tbody>
					</tgroup>
				</table>
			</para>
		</section>
	</section>

	<section id="uvmm::management">
		<title>Managing virtual machines with &ucsUMC;</title>
		<para>
			The UMC module <emphasis>Virtual machines (UVMM)</emphasis> offers the possibility to create, edit and delete virtual instances/machines and to change their status.

			In principle, these functions are independent of the virtualization technology employed (KVM or cloud-based), however they may vary slightly depending on the hypervisor in use.
			The items that must be observed are illustrated in the following section on the description of the functions.
		</para>

		<section id="uvmm::overview">
			<title>Operations (Starting/stopping/suspending/deleting/migrating/cloning virtual machines)</title>
			<figure id="uvmm-overview">
				<title>Overview of virtual machines</title>
				<graphic scalefit="1" width="90%" align="center" fileref="illustrations44/uvmm_overview1_en.png"/>
			</figure>
			<para>
				In the main dialogue of the UMC module, a tree structure is displayed on the left-hand side, which gives an overview of the existing virtualization servers.
				All the virtual machines are listed in the right half of the screen.
				If one clicks on the name of a virtualization server, only the instances of that server are listed.
				The search mask can also be used to search for individual virtual machines.
			</para>
			<para>
				In the overview of the virtual machines, the computer icon shows the state a virtual machine
				is in, e.g., whether it is running (computer symbol with green arrow), paused
				(computer symbol with yellow line) or stopped (computer without additional
				symbol).
				Virtual machines in cloud computing environments can also be depicted as deleted
				(computer with red cross) or as pending (computer with hourglass).
			</para>
			<para>
				The icon showing an arrow pointing right can be used to start a virtual instance.
			</para>

			<para>
			  Running instances can be accessed via the VNC protocol - insofar as this is
			  configured. The icon with the stylized screen opens a connection with noVNC, a
			  HTML5-based client. Any other VNC client can also be used for the access; the VNC port
			  is displayed in a tooltip above the computer name.
			</para>

			<para>
				The <guimenu>more</guimenu> choice box can be used to perform other operations:
				The following operations are available on running instances:
			</para>
			<variablelist>
				<varlistentry>
					<term>Stop</term>
					<listitem>
						<simpara>
						turns the virtual machine off.
						It must be noted that the operating system of the virtual machine is not shutdown first, i.e., it should be compared with turning off a computer by pulling the power plug.
						</simpara>
					</listitem>
				</varlistentry>
				<varlistentry>
					<term>Pause</term>
					<listitem>
						<simpara>
						assigns the instance no further CPU time.
						This still uses the working memory on the virtualization server, but the instance itself is paused.
						</simpara>
					</listitem>
				</varlistentry>
				<varlistentry>
					<term>Suspend</term>
					<listitem>
						<simpara>
						saves the contents of the machine's system memory on the hard drive and does not assign the machine further CPU time, i.e., compared with <guimenu>Pause</guimenu> the working memory is also freed.
						This function is only available on KVM-based virtualization servers.
						</simpara>
					</listitem>
				</varlistentry>
				<varlistentry>
					<term>Migrate</term>
					<listitem>
						<simpara>
						migrates the virtual machine to another virtualization server.
						Further information can be found in <xref linkend="uvmm:migration"/>.
						</simpara>
					</listitem>
				</varlistentry>
			</variablelist>
			<para>
				The following operations are available on saved or stopped instances:
			</para>
			<variablelist>
				<varlistentry>
					<term>Remove</term>
					<listitem>
						<simpara>
						Virtual instances no longer required can be deleted along with all their hard drives and ISO images.
						The images to be deleted can be selected from a list.
						It must be noted that ISO images and sometimes also hard drive images may still be used by other instances.
						They should only be deleted when they are no longer used by any instance.
						</simpara>
					</listitem>
				</varlistentry>
				<varlistentry>
					<term>Migrate</term>
					<listitem>
						<simpara>
						migrates the virtual machine to another virtualization server.
						Further information can be found in <xref linkend="uvmm:migration"/>.
						</simpara>
					</listitem>
				</varlistentry>
				<varlistentry>
					<term>Clone</term>
					<listitem>
						<simpara>
						creates a copy of the current VM. It is given a freely selectable,
					new name. Network interfaces are adopted, but can also alternatively be randomly
					regenerated. Mounted CD and DVD drives from the source VM are also integrated in
					the clone, while hard drives are copied insofar as the storage pool supports the
					copying. Snapshots are not copied!
						</simpara>
					</listitem>
				</varlistentry>
			</variablelist>
			<para>
				The following operations are available for virtual machines operated in
				cloud-based environments.
			</para>
			<variablelist>
				<varlistentry>
					<term>Restart (hard)</term>
					<listitem>
						<simpara>
							Restarts the virtual machine as if the reset button had been pressed. This can
							result in data loss.
						</simpara>
					</listitem>
				</varlistentry>
				<varlistentry>
					<term>Restart (soft)</term>
					<listitem>
						<simpara>
							Sends an ACPI reset event to the virtual machine. If the operating system of the
							virtual machine interprets this correctly, a regular restart is performed.
						</simpara>
					</listitem>
				</varlistentry>
				<varlistentry>
					<term>Shutdown (soft)</term>
					<listitem>
						<simpara>
							Sends an ACPI shutdown event to the virtual machine. If the operating system of
							the virtual machine interprets this correctly, it is shut down and turned off
							regularly.
						</simpara>
					</listitem>
				</varlistentry>
				<varlistentry>
					<term>Pause</term>
					<listitem>
						<simpara>
							The machine is not assigned any more CPU time. This still uses the working
							memory on the physical host, but the machine itself is paused.
						</simpara>
					</listitem>
				</varlistentry>
				<varlistentry>
					<term>Suspend</term>
					<listitem>
						<simpara>
							Saves the contents of the machine's working memory on the hard drive memory and
							does not assign the machine further CPU time, i.e., compared with
							<guimenu>Pause</guimenu>, the working memory is also freed.
						</simpara>
					</listitem>
				</varlistentry>
				<varlistentry>
					<term>Delete</term>
					<listitem>
						<simpara>
							Turns the virtual machine off and deletes all the corresponding data
							permanently.
						</simpara>
					</listitem>
				</varlistentry>
			</variablelist>
		</section>
		<section id="uvmm::cloudinstanz::erstellen">
			<title>Creating a virtual machine via a cloud connection</title>
			<para>
				Virtual machines in cloud-based virtualization environments can be created in
				just a few steps in UVMM using the wizard by clicking on <guimenu>Create</guimenu>.
			</para>
			<para>
				In the <guimenu>Create a virtual machine or a cloud connection</guimenu> input
				mask you can select the cloud connection via which you wish to create the
				virtual machine. Once a connection has been selected and you have clicked on
				<guimenu>Next</guimenu>, the wizard for creating a new virtual machine opens.
				Once the parameters have been set, the new virtual machine is created by
				clicking on <guimenu>Finish</guimenu>.
			</para>
			<table>
				<title>Creating a virtual machine via a cloud connection</title>
				<tgroup cols="2">
					<colspec colnum="1" colname="col1" colwidth="1*"/>
					<colspec colnum="2" colname="col2" colwidth="2*"/>
					<thead>
						<row>
							<entry>Attribute</entry>
							<entry>Description</entry>
						</row>
					</thead>
					<tbody>
						<row>
							<entry>Name</entry>
							<entry>
								Defines the name of the virtual machine
							</entry>
						</row>
						<row>
							<entry>Choose a source image / source AMI</entry>
							<entry>
								The initial status of a virtual machine when created is specified via a source
								image (OpenStack) or source AMI (EC2). This type of image usually includes a
								prepared operating systems that the user can customize after the start-up. Any
								number of virtual machines can be created from one source image.
							</entry>
						</row>
						<row>
							<entry>Choose an instance size</entry>
							<entry>
								An instance size is assigned to a virtual machine when it is created. This is
								composed of available memory and the size of the available hard drive memory.
								When a virtual machine is created in an OpenStack environment, the number of the
								CPU cores is also determined when selecting the size.
							</entry>
						</row>
						<row>
							<entry>Select a key pair</entry>
							<entry>
								To allow safe access to the virtual machine via ssh, an ssh key for
								configuration of the root account is added to the machine the first time it is
								started. With this key, it is possible to access the machine via ssh without a
								password. For this to happen, there must be access to the private key part of
								the key pair. The access to the instance can be performed with the following
								command, for example, if the instance is running:
								<programlisting language="sh">
ssh -i [path/to/private/key] root@[instance-ip-address]
								</programlisting>
							</entry>
						</row>
						<row>
							<entry>Configure security group</entry>
							<entry>
								This setting configures which security group is set for the new virtual machine.
								A security group determines which TCP ports are approved for external access to
								a virtual machine.
							</entry>
						</row>
					</tbody>
				</tgroup>
			</table>
		</section>
		<section id="uvmm::cloudinstanz::bearbeiten">
			<title>Editing a virtual machine via a cloud connection</title>
			<para>
				By selecting a virtual machine and clicking on <guimenu>Edit</guimenu> you can
				view the configured settings of the virtual machine on a separate page. The IP
				address via which the virtual machine can be reached is shown here in
				particular.
			</para>
		</section>
		<section id="uvmm::instanz::erstellen">
			<title>Creating a virtual instance</title>
			<para>
				Virtual machines on local KVM servers can be created with the assistant in a few steps in UVMM by clicking on <guimenu>Create</guimenu>.
			</para>
			<para>
				In the <guimenu>Create a virtual machine or a cloud connection</guimenu> input
				mask you can select the virtualization server on which you wish to create the
				virtual machine. If a KVM virtualization server is selected here and
				<guimenu>Continue</guimenu> clicked, the machine profile selection page opens.

				The selection of the <guimenu>Profile</guimenu> specifies some
				of the basic settings for the virtual instance (see <xref
				linkend="uvmm::profile"/>).
			</para>
			<para>
				The virtual machine is now given a <guimenu>Name</guimenu> and an optional <guimenu>Description</guimenu> and assigned <guimenu>Memory</guimenu> and <guimenu>CPUs</guimenu>.

				The <guimenu>Enable direct access</guimenu> option specifies whether the machine can be accessed via the VNC protocol.
				This is generally required for the initial operating system installation.
			</para>
			<para>
				Now the disk drives of the virtual machines are configured.
				The setup is documented in <xref linkend="uvmm:imagefiles"/>.
			</para>
			<para>
				Clicking <guimenu>Finish</guimenu> concludes the creation of the virtual machine.
		</para>
	</section>

	<section id="uvmm-instance-edit">
		<title>Modifying virtual machines</title>
		<para>
			In the overview list, a virtual machine can be edited by clicking on the icon with the stylized pen.
		</para>
		<figure id="uvmm-drive">
			<title>Modifying the settings of a DVD drive</title>
			<graphic scalefit="1" width="70%" align="center" fileref="illustrations44/uvmm_dvd_en.png"/>
		</figure>
		<para>
		  Most settings of a virtual machine can only be changed if it is turned off.
		</para>
			<table>
				<title>'General' tab</title>
				<tgroup cols="2">
					<colspec colnum="1" colname="col1" colwidth="1*"/>
					<colspec colnum="2" colname="col2" colwidth="2*"/>
					<thead>
						<row>
							<entry>Attribute</entry>
							<entry>Description</entry>
						</row>
					</thead>
					<tbody>
						<row>
							<entry>Name</entry>
							<entry>
								Defines the name of the virtual machine.
								This does not have to be the same as the name of the host in the LDAP directory.
							</entry>
						</row>
						<row>
							<entry>Operating system</entry>
							<entry>
								The operating system installed in the virtual instance.
								Any text can be entered here.
							</entry>
						</row>
						<row>
							<entry>Contact</entry>
							<entry>
								Defines the contact person for the virtual machine.
								If an e-mail address is specified here, an external e-mail program can then be run via the mouseover that appears.
							</entry>
						</row>
						<row>
							<entry>Description</entry>
							<entry>
							  Can be used to describe the function of the virtual machine,
							  e.g. <emphasis>mail server</emphasis> or it's state. The description
							  is shown in the overview of the virtual machines as a mouseover.
							</entry>
						</row>
					</tbody>
				</tgroup>
			</table>

			<para>
			  The tab <guimenu>Devices</guimenu> allows the
			  configuration of drives and network interfaces. An
			  introduction to the supported devices, image formats and
			  storage pools can be found in the <xref
			  linkend="uvmm:imagefiles"/>. An introduction to the
			  supported network card settings can be found in the
			  <xref linkend="uvmm:networkinterfaces"/>.
			</para>
			<para>
				<guimenu>Drives</guimenu> lists all existing drives, the image files used, their size and the assigned storage pools.
				One can click on the stylized minus sign to delete a drive and <guimenu>Edit</guimenu> can be used to adjust setting subsequently.
			</para>
			<para>
				<guimenu>Paravirtual drive</guimenu> allows specification of whether the access to the drive should be paravirtualized.
				Where possible, this setting should not be changed for a virtual machine which already has an operating system installed, as this may disrupt the access of partitions.
			</para>
			<para>
				If drives or network interfaces are subsequently added to a virtual instance, the utilization of paravirtualization is determined by heuristics or its profile.
			</para>
			<para>
				<guimenu>Add drive</guimenu> can be used to add an additional drive.
			</para>
			<para>
				This menu contains a list of all network cards; in addition, new cards can be added or existing ones edited.
				<guimenu>Add network interface</guimenu> can be used to add another virtual network card.
			</para>

			<para>
			  The tab <guimenu>Snapshots</guimenu> contains a list of all available snapshots.
			  An introduction to snapshots can be found in the <xref linkend="uvmm::snapshots"/>.
			</para>
			<para>
				<guimenu>Snapshots</guimenu> includes a list of all the existing snapshots.
				<guimenu>Resume</guimenu> can be used to restore an earlier status.
			</para>
			<caution>
				<para>
				The current machine state is lost if the old snapshot is restored.
				However, there is no reason not to save the current state in an additional snapshot in advance.
				</para>
			</caution>
			<para>
				A snapshot can be removed by clicking in the stylized minus sign.
				The current state of the virtual machine is not modified by this.
			</para>
			<para>
				<guimenu>Create new snapshot</guimenu> can be used to create a snapshot with the name of your choice, e.g., <emphasis>DC Master before update to UCS 4.0-1</emphasis>.
				In addition to the description the time is saved when the snapshot is created.
			</para>

			<para>
				The tab <guimenu>Migration targethosts</guimenu> can be used to configure the host systems, to which the virtual machine can be migrated to.
				Further information on migration can be found in <xref linkend="uvmm:migration"/>.
			</para>

			<table>
				<title>'Advanced' tab</title>
				<tgroup cols="2">
					<colspec colnum="1" colname="col1" colwidth="1*"/>
					<colspec colnum="2" colname="col2" colwidth="2*"/>
					<thead>
						<row>
							<entry>Attribute</entry>
							<entry>Description</entry>
						</row>
					</thead>
					<tbody>
						<row>
							<entry>Architecture</entry>
							<entry>
								Specifies the architecture of the emulated hardware.
								It must be noted that virtual 64-bit machines can only be created on virtualization servers using the amd64 architecture.
								This setting is not shown on i386  systems.
							</entry>
						</row>
						<row>
							<entry>Number of CPUs</entry>
							<entry>
								Defines how many CPU sockets are assigned to the virtual instance.
								The number of NUMA nodes, cores and CPU threads is not currently configurable.
							</entry>
						</row>
						<row>
							<entry>CPU model</entry>
							<entry>
								The CPU model for the virtual machine.
								The list of usable models depends on the concrete host system.
								A complete list of available models is available on the command line running <command>virsh domcapabilities</command>.
								Further information - especially on live migration - see <xref linkend="uvmm:migration"/>.
							</entry>
						</row>
						<row>
							<entry>Memory</entry>
							<entry>
								Specifies the size of the assigned system memory.
							</entry>
						</row>
						<row>
							<entry>Virtualization technology</entry>
							<entry>
								The technology used for virtualization.
								This setting can only be specified when creating a virtual instance.
							</entry>
						</row>
						<row>
							<entry>RTC reference</entry>
							<entry>
								In fully virtualized systems, a computer clock is emulated for each virtual machine (paravirtualized systems access the clock on the host system directly).
								This option controls the format of the emulated clock;
								it an either be saved in the <guimenu>coordinated universal time (UTC)</guimenu> or the <guimenu>local timezone</guimenu>.
								The use of UTC is recommended for Linux system and the use of the local time zone recommended for Microsoft Windows systems.
							</entry>
						</row>
						<row>
							<entry>Boot order</entry>
							<entry>
								Specifies the order in which the emulated BIOS of the virtual machine searches the drives for bootable media.
								This setting is only available for fully-virtualized instances.
								On paravirtualized machines it is only possible to select one hard drive from which the kernel should be used.
							</entry>
						</row>
						<row>
							<entry>Enable Hyper-V Enlightenment</entry>
							<entry>
								Allow guest systems like <systemitem class="osname">Microsoft Windows</systemitem> to run more efficient as virtual machines.
							</entry>
						</row>
						<row>
							<entry>Always start VM with host</entry>
							<entry>
								Defines whether the virtual machine is automatically started when the host systems itself starts up.
							</entry>
						</row>
						<row>
							<entry>Direct access (VNC)</entry>
							<entry>
							  Defines whether VNC access to the virtual machine is available. If the
							  option is enabled, the virtual machine can be accessed directly via
							  the UMC module using an HTML5-based VNC client or any other VNC client.
							  The VNC URL is displayed in a tool tip.
							</entry>
						</row>
						<row>
							<entry>Globally available</entry>
							<entry>
								This allows VNC access from other systems than the virtualization server.
							</entry>
						</row>
						<row>
							<entry>VNC Password</entry>
							<entry>
								Sets a password for the VNC connection.
							</entry>
						</row>
						<row>
							<entry>Keyboard layout</entry>
							<entry>
								Defines the layout for the keyboard in the VNC session.
							</entry>
						</row>
					</tbody>
				</tgroup>
			</table>
		</section>
	</section>

	<section id="uvmm:kvmfeatures">
		<title>KVM related UVMM features</title>
		<section id="uvmm:imagefiles">
			<title>Image files of virtual machines</title>
			<para>
				If virtual hard drives are added to an instance, <emphasis>image files</emphasis> are usually used for the data keeping.
				An image file can either be generated for this purpose or an existing image file can be assigned to a virtual machine.
				Alternatively, a native block device (hard drive partition, logical volume, iSCSI volume) can be assigned to a virtual machine.
				The direct use of block devices offers performance advantages and is less susceptible to computer crashes.
			</para>
			<para>
				Hard drive images can be administrated in two ways on KVM systems;
				by default images are saved in the <guimenuitem>Extended format (qcow2)</guimenuitem>.
				This format supports Copy-on-write which means that changes do not overwrite the original version, but store new versions in different locations.
				The internal references of the file administration are then updated to allow both access to the original and the new version.
				Snapshots can only be created when using hard drive images in <guimenuitem>Extended format</guimenuitem>.
				Alternatively, you can also access a hard drive image in <guimenuitem>Simple format (raw)</guimenuitem>.
			</para>
			<para>
			  Operating systems use a so-called <emphasis>page cache</emphasis> to accelerate accesses
			  to storage media. If data are accessed which have already been read off a hard drive and
			  these data are still present in the cache, the comparatively slow access to the storage
			  medium is not necessary and the request is answered directly from the page cache.
			</para>

			<para>
			  Write accesses are generally also not directly written on the hard drive, but are usually
			  bundled and, consequently, written more efficiently. However, this involves the risk of
			  data loss, if, for example, a system crashes or the power supply is interrupted. The data
			  which have been only saved in the write cache up to that point and have yet to be
			  synchronized on the storage medium are lost. For this reasons, modern operating systems
			  generally only keep pending write changes for a maximum of several seconds before writing
			  them to the hard drive.
			</para>

			<para>
			  In order to avoid data being stored doubly in the page cache of the host system and also
			  of the guest system, cache strategies can be configured with the
			  <guimenu>Caching</guimenu> option when using KVM, which influence the use of the host
			  system's page cache:
			</para>

			<itemizedlist>
				<listitem>
					<simpara>
				  The default setting since UCS-3.1 is <guimenuitem>none</guimenuitem>: in this setting, KVM
				  accesses the hard drive directly and bypasses the page cache on the virtualization
				  server.<!--footnote><para>This strategy does not work on file systems using <literal>tmpfs</literal> or with some <acronym>NFS</acronym> servers.</para></footnote--> Read accesses are answered directly by the hard drive every time and write
				  accesses are passed directly on to the hard drive.
					</simpara>
				</listitem>

				<listitem>
					<simpara>
				  The <guimenuitem>write-through</guimenuitem> strategy uses the page cache on the
				  virtualization server, but every write access is also passed on directly to the
				  storage medium. On virtualization servers with a lot of free system memory, read
				  accesses can be more efficient than <guimenuitem>none</guimenuitem>. However, the double
				  caching generally has a negative effect on the overall performance.

				  <footnote><para>Instead, it is recommended to make the free memory directly available
				  to the VMs so that they can use the additional memory more efficiently themselves, for
				  instance for caching.</para></footnote>
					</simpara>
				</listitem>

				<listitem>
					<simpara>
				  If the <guimenuitem>write-back</guimenuitem> strategy is used, the host's page cache will
				  be used for both read and write accesses. Write accesses are initially only performed
				  in the page cache, before they are then written to the hard drive at a later point in
				  time. In this case, if the host system crashes, data may be lost.
					</simpara>
				</listitem>

				<listitem>
					<simpara>
				  With the <guimenuitem>unsafe</guimenuitem> strategy, synchronization requests sent by the
				  guest system are ignored in order to force the writing of outstanding data on the
				  storage medium explicitly. Compared with <guimenuitem>write-back</guimenuitem>, this once
				  again increases the performance, but can result in data loss if the host system
				  crashes. This version is only practical for test systems or comparable installations
				  in which data loss due to the crashing of the host system is not dramatic.
					</simpara>
				</listitem>

				<listitem>
					<simpara>
				  The <guimenuitem>directsync</guimenuitem> strategy corresponds to <guimenuitem>none</guimenuitem>,
				  with the only difference being that here synchronization is explicitly forced after
				  every write access.
					</simpara>
				</listitem>

				<listitem>
					<simpara>
				  The <guimenuitem>Hypervisor default</guimenuitem> option is dependent on the UCS version and
				  the KVM version with which a guest system was installed: Originally, the standard
				  value until UCS 3.0 was implicitly <guimenuitem>write-through</guimenuitem>, but KVM was
				  modified to such an extent with UCS 3.1 that <guimenuitem>none</guimenuitem> is now used for
				  all old VMs instead. For VMs re-saved with UCS 3.1 the standard value is implicitly
				  <guimenuitem>write-through</guimenuitem> again, but new VMs are explicitly saved with
				  <guimenuitem>none</guimenuitem>.
					</simpara>
				</listitem>
			</itemizedlist>
			<para>
				If a live migration of virtual machines between different virtualization servers is planned, the storage pool must be stored on a system which can be accessed by all virtualization servers (e.g., an NFS share or an iSCSI target).
				This is described in <xref linkend="uvmm::storagepools"/>.
			</para>
			<para>
				Image files are created as sparse files with the specified size, i.e., these files only grow when they are used and then up to the maximally specified size and thus initially require only minimal disk space.
				As there is a risk here of the disk space being used up during operation, a Nagios monitoring should be integrated, see <xref linkend="nagios::general"/>.
			</para>
			<para>
				Where possible, hard drive images should be configured paravirtualized. In the
				case of UCS systems installed virtualized in KVM, a paravirtualized access is
				activated automatically when the UCS profile is selected. The configuration of
				Microsoft Windows systems is documented in <xref linkend="uvmm::gplpvvirtio"/>.
			</para>
		</section>

		<section id="uvmm::storagepools">
		  <title>Storage pools</title>

		  <para>
			These image files are stored in so-called storage pools. They can either be stored locally
			on the virtualization server or on a file share. The connection of a storage pool over iSCSI
			is documented in <xref linkend="ext-doc-uvmm"/>.
		  </para>

		  <section id="uvmm::defaultpool">
			<title>Accessing the default storage pool through a file share</title>
			<para>
			  Each virtualization server provides a storage pool with the name
			  <wordasword>default</wordasword> in the standard configuration. It can be found on the
			  virtualization servers in the <filename class="directory">/var/lib/libvirt/images/</filename> directory.
			</para>

			<para>
			  To allow simple access to the storage pool, you can set up a share for the
			  <filename class="directory">/var/lib/libvirt/images/</filename> directory. To do so, you need to create a
			  share with the following options in the UMC module <guimenu>Shares</guimenu>. The share
			  can then be accessed easily from Windows clients via a CIFS network share (or via an NFS
			  mount).
			</para>
			<itemizedlist>
				<listitem>
					<para>General/General settings</para>
					<itemizedlist>
						<listitem><simpara>Name: <userinput>UVMM-Pool</userinput></simpara></listitem>
						<listitem><simpara>Host: The hostname of the UVMM server</simpara></listitem>
						<listitem><simpara>Directory: <userinput>/var/lib/libvirt/images</userinput></simpara></listitem>
						<listitem><simpara>Directory owner, Directory owner group and Directory mode can remain in the default setting</simpara></listitem>
					</itemizedlist>
				</listitem>
				<listitem>
					<para>Advanced settings/Samba permissions</para>
					<itemizedlist>
						<listitem><simpara>Valid users or groups: <userinput>Administrator</userinput></simpara></listitem>
					</itemizedlist>
				</listitem>
			</itemizedlist>
			<para>
			  The image files of a virtual hard drive include all the user data of the virtualized
			  system! The <guimenu>Valid users or groups</guimenu> option ensures that, irrespective
			  of the file system permissions, only the Administrator user can access the share.
			</para>
		  </section>

		  <section id="uvmm::addpool">
			<title>Adding a storage pool</title>
			<para>
			  It is not possible to create an additional storage pool via &ucsUMC;. Instead, this
			  must be done by logging in to the virtualization server as the <systemitem class="username">root</systemitem>
			  user. The following steps are required for this:

			  <itemizedlist>
				<listitem><simpara>
				  The directory in which the data from the storage pool are to be saved must be created;
				  in this case <filename class="directory">/mnt/storage/</filename>.
				</simpara></listitem>

				<listitem><simpara>
				  The following command is used to create the new <wordasword>Testpool</wordasword> storage pool:
				  </simpara>
				  <programlisting language="sh">
virsh pool-define-as Testpool dir - - - - "/mnt/storage"
				  </programlisting>
				</listitem>

				<listitem><simpara>
				  The libvirt library used by UVMM differentiates between active and inactive storage
				  pools. To be able to use the storage pool directly, it must be activated:
				  </simpara>
				  <programlisting language="sh">
virsh pool-start Testpool
				  </programlisting>
				  <simpara>
				  The following command ensures that the pool is activated automatically the next time
				  the system is started:
				  </simpara>
				  <programlisting language="sh">
virsh pool-autostart Testpool
				  </programlisting>
				</listitem>
			  </itemizedlist>
			</para>
		  </section>

		  <section id="uvmm::movepool">
			<title>Moving the default storage pool</title>
			<para>
			  To change the underlying file path of the default storage pool at a later point in time,
			  one must log in to the virtualization server as the <systemitem class="username">root</systemitem> user. The
			  following steps are required for this:

			  <itemizedlist>
				<listitem><simpara>
				  The &ucsUCRV; <envar>uvmm/pool/default/path</envar> must be changed to the new directory.
				</simpara></listitem>

				<listitem><simpara>
				  The following commands remove the old storage pool; the pool is changed over to the
				  new path the next time the UVMM is restarted:
				  </simpara>
				  <programlisting language="sh">
virsh pool-destroy default
virsh pool-undefine default
invoke-rc.d univention-virtual-machine-manager-daemon restart
invoke-rc.d univention-virtual-machine-manager-node-common restart
				  </programlisting>
				</listitem>
			  </itemizedlist>
			</para>
		  </section>
		</section>

		<section id="uvmm::drives">
			<title>CD/DVD/floppy drives in virtual machines</title>
			<para>
				CD-/DVD-ROM/floppy drives can be mounted in two ways:
			</para>
			<itemizedlist>
				<listitem>
					<simpara>
					An ISO image can be assigned from a storage pool. If no additional storage pool has
					been created, the files from the pool <emphasis>default</emphasis> are read from the
					directory <filename class="directory">/var/lib/libvirt/images/</filename>.
					</simpara>
				</listitem>
				<listitem>
					<simpara>
					Alternatively, a physical drive from the virtualization server can be connected with the virtual machine.
					</simpara>
				</listitem>
			</itemizedlist>
			<para>
				It is also possible to provide a virtual machine with a disk drive via an image (in <filename class="extension">VFD</filename> format) or the pass-through of a physical drive.
			</para>
			<para>
				If drives are defined for a new virtual machine, it must be ensured that it is possible to boot from the CD-ROM drive.
				The UVMM profile (see <xref linkend="uvmm::profile"/>) specifies the boot order for the fully-virtualized instances in advance.
				For the paravirtualized instances, it is defined by the order on the definition of the drives and can be adapted subsequently in the settings section.
			</para>
		</section>

		<section id="uvmm:networkinterfaces">
			<title>Network interfaces in virtual instances</title>
			<para>
				When a virtual machine is created, it is automatically assigned a network card with a randomly generated MAC address.
				It can be subsequently changed.
			</para>
			<para>
				Two types of network connections are possible:
			</para>
			<itemizedlist>
				<listitem>
					<simpara>
					In the basic settings, a <emphasis>Bridge</emphasis> on the virtualization server is used to access the network directly.
					The virtual machine uses its own IP address and can thus also be reached from other computers.
					</simpara>
				</listitem>
				<listitem>
					<simpara>
					<emphasis>Network Address Translation (NAT)</emphasis> network cards are defined in a private network on the virtualization server.
					To do so, the virtual machine(s) must be assigned an IP address from the <systemitem class="ipaddress">192.0.2.0/24</systemitem> network.
					This virtual instance is granted the access to the external network via NAT, so that the access is performed via the virtualization server's IP address.
					The virtual machine can thus not be reached from other computers, but can create all outgoing connections itself.
					</simpara>
				</listitem>
			</itemizedlist>
			<figure id="uvmm-network">
				<title>Adding a virtual network interface</title>
				<graphic scalefit="1" width="70%" align="center" fileref="illustrations44/uvmm_network_en.png"/>
			</figure>
			<para>
				The UVMM servers are already preconfigured for bridging and NAT.
				However, there are restrictions for bridged network cards which are described in <xref linkend="computers:networkcomplex:uvmm"/>.
				For each virtual machine the desired network can be selected through the <guimenu>Source</guimenu> setting.
			</para>
			<para>
				NAT network cards are only restricted by the IP addresses available in the <systemitem class="ipaddress">192.0.2.0/24</systemitem> network.
			</para>
			<para>
				The <guimenu>Driver</guimenu> can be used to select what type of card will be provided.
				The <guimenuitem>Realtek RTL-8139</guimenuitem> is supported by almost all operating systems, the <guimenuitem>Intel Pro-1000</guimenuitem> offers advanced abilities and a <guimenuitem>Paravirtual device</guimenuitem> offers the best performance.
			</para>
		</section>

		<section id="uvmm::gplpvvirtio">
			<title>Paravirtualization (virtIO) drivers for Microsoft Windows systems</title>
			<para>
				KVM supports paravirtualization via the virtIO interface. The use of
				paravirtualization allows the virtualized systems direct access to the resources
				of the virtualization server. This considerably improves performance. We
				recommend the use of paravirtualization.
			</para>
			<para>
				Current Linux systems support paravirtualization as standard. The installation
				of the KVM packages provides suitable images which can then be mounted in a
				virtual machine in the disk management. The images are integrated in the storage
				area specified by the &ucsUCRV; <envar>uvmm/pool/default/patht</envar>. On KVM
				virtualization servers, there is an ISO image with the name <emphasis>KVM
				Windows drivers</emphasis>, which contains the virtIO virtualization drivers for
				Microsoft Windows.
			</para>
			<section id="uvmm:virtio">
				<title>Installation of the virtIO drivers for KVM instances</title>
				<para>
					In Windows systems installed under KVM, paravirtualization must be activated <emphasis>before</emphasis> beginning the Windows installation.
				</para>
				<para>
					The virtIO interface allows the efficient usage of network and storage resources for a virtual machine on the KVM hypervisor.
					The following steps describe the installation of the virtIO drivers on Windows 7.
				</para>
				<itemizedlist>
					<listitem>
						<simpara>
						A CD/DVD drive needs to be setup in the drive settings with the image <guimenuitem>KVM Windows drivers</guimenuitem> assigned.
						</simpara>
					</listitem>
					<listitem>
						<simpara>
						The hard disk drive has to be edited in the <guimenu>Devices</guimenu> menu in UVMM and the checkbox <guimenuitem>Paravirtual drive</guimenuitem> must be ticked.
						</simpara>
					</listitem>

					<listitem><simpara>
					  The <guimenu>Driver</guimenu> must be configured to <guimenuitem>Paravirtual device
					  (virtio)</guimenuitem> for the network card(s).
					</simpara></listitem>

					<listitem>
						<simpara>
						The initial steps during the installation of the Windows system take place as usual.
						A warning appears during hard disk partitioning and states that no mass storage could be found.
						This is not an error because the virtIO drivers are necessary for a paravirtualized device.
						The virtIO drivers can be installed in the same menu with <guimenu>Load drivers</guimenu>.
						The <guimenuitem>Red Hat virtIO SCSI Controller</guimenuitem> has to be chosen for Windows 7 (and for Windows 2003 and Windows 2008 respectively) and the <guimenuitem>Red Hat virtIO Ethernet Adapter</guimenuitem> for Windows 2008/Windows 7.
						After the device drivers have been installed, the mass storage is available in the Windows installer and the installation of Microsoft Windows can be continued.
						</simpara>
					</listitem>
					<listitem>
						<simpara>
						After completing the installation the devices <computeroutput>Red Hat virtIO SCSI Disk Device</computeroutput> and <computeroutput>Red Hat virtIO Ethernet Adapter</computeroutput> can be found in the Windows device manager.
						</simpara>
					</listitem>
				</itemizedlist>
			</section>
		</section>

		<section id="uvmm::snapshots">
			<title>Snapshots</title>
			<para>
				UVMM offers the possibility to save the contents of the main and hard drive memory of a virtual machine in snapshots.
				This allows the administrator to revert to these snapshots at a later point in time, which makes them a useful "safety net" when installing software updates.
			</para>
			<para>
				Snapshots can only be used with KVM instances which access all their hard drive images in Qcow2 format.
				All snapshots are stored using copy-on-write (see <xref linkend="uvmm::instanz::erstellen"/>) directly in the hard drive image file.
			</para>
		</section>

		<section id="uvmm:migration">
			<title>Migration of virtual instances</title>
			<para>
				UVMM offers the the possibility of migrating a virtual machine to another virtualization server.
				This works with both paused and running instances (live migration).
				The option is only offered if at least two compatible virtualization servers are available in the domain.
			</para>
			<figure id="uvmm-migrate">
				<title>Migrating a virtual instance</title>
				<graphic scalefit="1" width="40%" align="center" fileref="illustrations44/uvmm_migrate_en.png"/>
			</figure>
			<para>
				During the migration it must be noted that the images of the mounted hard drives and CD-ROM drive must be accessible by both virtualization servers.
				This can be achieved, for example, by storing the images in a central storage system.
				Notes on the setting up of this type of environment can be found under <xref linkend="uvmm::storagepools"/>.
			</para>
			<section id="uvmm:Migration_of_virtual_machines_from_failed_virtualization_servers">
				<title>Migration of virtual machines from failed virtualization servers</title>
				<para>
					Information about the virtual machines running on the virtualization servers is stored centrally in the &ucsUVMM;.
					If a server fails (failure detection is performed periodically every 15 seconds), the server and the virtual instances operated on it are identified as inaccessible with a red symbol, a warning appears and <guimenu>Migrate</guimenu> is offered as the only operation in the menu.
				</para>
				<para>
					Following the migration, the virtual instance is no longer displayed in the overview tree of the failed virtualization server in the UVMM.
				</para>
				<caution>
					<para>
					It must be ensured under all circumstances that the virtual machine on the original and the secondary server are not started in parallel; this would involve their both writing in the image files simultaneously, which would result in data loss.
					If virtual machines are started automatically after startup, simultaneous access must be prohibited by disconnecting the network connection or restricting access to the storage pool.
					</para>
				</caution>
				<para>
					If the failed computer is reactivated - e.g., in the case of a temporary power failure - the virtual machines remain available on the system locally and are reported to UVMM; consequently, there are then two versions of the instance.
				</para>
				<para>
					As such, one of the two instances should subsequently be deleted.
					However, the employed image files for the drives should <emphasis>not</emphasis> be deleted at the same time.
				</para>
			</section>
			<section id="uvmm:migration:cpu">
				<title>Migration of virtual machines between hosts with different CPUs</title>
				<para>
					Virtual machines can be migrated between hosts with compatible CPUs.
					Newer CPUs are normally backwards compatible with previous generations of the CPU and only gain new features.
					The reverse is not true:
					If the guest operating system has decided to use a new feature and that feature does no longer work after migration, the virtual machine will crash.
				</para>
				<para>
					By default, no specific CPU model is explicitly configured:
					Rather, the CPU functions of the respective virtualization server are passed directly to the virtual machine.
					The advantage is that the performance is higher, the disadvantage is that it can lead to crashes during live migration.
					To prevent migration between incompatible CPUs, UVMM can consider the CPU model of the server.
					This functionality has to be configured per virtual machine and only becomes effective after a restart of the virtual machine.
					A reboot of the running guest operating system is not sufficient;
					The virtual machine must be turned off if necessary and must be started again.
				</para>
				<para>
					On the <guimenu>Advanced</guimenu> tab of the virtual machine the CPU model can be configured explicitly.
				</para>
				<para>
					Using &ucsUCRV; <envar>uvmm/vm/cpu/host-model</envar> the required customization of virtual machines can be automated.
					The following values can be used:
				</para>
				<variablelist>
					<varlistentry>
						<term><literal>missing</literal></term>
						<listitem>
							<simpara>
								UVMM activates the check for all virtual machines for which the CPU model is not already explicitly configured.
							</simpara>
						</listitem>
					</varlistentry>
					<varlistentry>
						<term><literal>always</literal></term>
						<listitem>
							<simpara>
								UVMM activates the check for all virtual machines, regardless of whether a CPU model is already explicitly configured or not.
								This will overwrite any previous CPU model configuration.
							</simpara>
						</listitem>
					</varlistentry>
					<varlistentry>
						<term><literal>remove</literal></term>
						<listitem>
							<simpara>
								UVMM removes any CPU model configurations.
							</simpara>
						</listitem>
					</varlistentry>
					<varlistentry>
						<term>- unset -</term>
						<listitem>
							<simpara>
								UVMM does not reconfigure any virtual machine.
								This is the default.
							</simpara>
						</listitem>
					</varlistentry>
				</variablelist>
				<caution>
					<para>
						If multiple UVMM daemons are used, &ucsUCRV; <envar>uvmm/vm/cpu/host-model</envar> should be set identically on all UCS systems.
					</para>
				</caution>
			</section>
		</section>
	</section>

	<section id="uvmm::profile">
		<title>Profiles</title>
		<para>
			Profiles are used to store initial settings when creating new virtual machines.
			Among others this includes the following settings:
		</para>
		<itemizedlist>
			<listitem><simpara>name prefix for new virtual machines</simpara></listitem>
			<listitem><simpara>number of virtual <acronym>CPU</acronym>s</simpara></listitem>
			<listitem><simpara><acronym>CPU</acronym> model</simpara></listitem>
			<listitem><simpara>default RAM size</simpara></listitem>
			<listitem><simpara>default size for new disk images</simpara></listitem>
			<listitem><simpara>default boot order for fully-virtualized virtual machines</simpara></listitem>
			<listitem><simpara>use of paravirtual device drivers</simpara></listitem>
			<listitem><simpara>default settings for direct access per <acronym>VNC</acronym></simpara></listitem>
			<listitem><simpara>network bridge name</simpara></listitem>
		</itemizedlist>
		<para>
			The existing UVMM profiles are stored in the <acronym>LDAP</acronym> directory and can also be edited there.
			The profiles can be found in the UMC module <guimenu>LDAP directory</guimenu> in the container <uri>cn=Profiles,cn=Virtual Machine Manager</uri>.
			Additional profiles can also be added there.
		</para>
		<section id="uvmm::profile::network">
			<title>Changing default network</title>
			<para>
				The name of the bridge used as the default network interface is stored in <acronym>UVMM</acronym> profiles.
				If the default interface <filename class="devicefile">br0</filename> is changed, the name should be updated as well.
				The following command updates all profiles currently using interface <filename class="devicefile"><replaceable>$OLD</replaceable></filename> to use the bridge <filename class="devicefile"><replaceable>$NEW</replaceable></filename>:
			</para>
			<programlisting language="sh">
udm uvmm/profile list --filter interface="$OLD" |
	sed -ne 's/^DN: //p' |
	xargs -r -d '\n' -n 1 udm uvmm/profile modify --set interface="$NEW" --dn
			</programlisting>
		</section>
	</section>
</chapter>
